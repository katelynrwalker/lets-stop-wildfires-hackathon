{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dropout, Dense, Input, Lambda, MaxPooling2D, Conv2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#create a base model\n",
    "image_width=224\n",
    "image_height=224\n",
    "IMAGE_SHAPE = (image_width, image_height, 3)\n",
    "base_model = VGG16(input_shape=IMAGE_SHAPE, include_top=False,weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 7, 7, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-665b7d358ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/train_data_set/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# report details about the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_files' is not defined"
     ]
    }
   ],
   "source": [
    "# example of loading an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "# load the image\n",
    "img = load_img('../data/train_data_set/'+train_files[0])\n",
    "# report details about the image\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "# show the image\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "float32\n",
      "(2048, 3072, 3)\n",
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "# example of converting an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "# load the image\n",
    "img = load_img('data/train_data_set/'+train_files[0])\n",
    "print(type(img))\n",
    "# convert to numpy array\n",
    "img_array = img_to_array(img)\n",
    "print(img_array.dtype)\n",
    "print(img_array.shape)\n",
    "# convert back to image\n",
    "img_pil = array_to_img(img_array)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img.rotate(90)\n",
    "img2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/katelynwalker/Projects/wildfire/lets-stop-wildfires-hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd lets-stop-wildfires-hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mREADME.md\u001b[m\u001b[m                              mapping.csv\n",
      "\u001b[31mcalculate_image_difference.ipynb\u001b[m\u001b[m       one_shot_network.ipynb\n",
      "\u001b[34mcheckpoints\u001b[m\u001b[m                            smoke_pairs.csv\n",
      "combinations.csv                       wildfire_smoke_challenge_1A.ipynb\n",
      "create_validation_set.ipynb            wildfire_smoke_challenge_1A_will.ipynb\n",
      "\u001b[34mdiff\u001b[m\u001b[m                                   wildfire_smoke_challenge_1B.ipynb\n",
      "\u001b[31mfind_combinations.ipynb\u001b[m\u001b[m                wildfire_smoke_challenge_2_kw_ac.ipynb\n",
      "\u001b[34mimg\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = pd.read_csv(\"smoke_pairs.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fPath1</th>\n",
       "      <th>fPath2</th>\n",
       "      <th>label</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>../data/train_data_set/20170625-BBM-bm-n-mobo/...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             fPath1  \\\n",
       "0           0  ../data/train_data_set/20170625-BBM-bm-n-mobo/...   \n",
       "1           1  ../data/train_data_set/20170625-BBM-bm-n-mobo/...   \n",
       "2           2  ../data/train_data_set/20170625-BBM-bm-n-mobo/...   \n",
       "3           3  ../data/train_data_set/20170625-BBM-bm-n-mobo/...   \n",
       "4           4  ../data/train_data_set/20170625-BBM-bm-n-mobo/...   \n",
       "\n",
       "                                              fPath2  label  test_label  \n",
       "0  ../data/train_data_set/20170625-BBM-bm-n-mobo/...      0       False  \n",
       "1  ../data/train_data_set/20170625-BBM-bm-n-mobo/...      0       False  \n",
       "2  ../data/train_data_set/20170625-BBM-bm-n-mobo/...      0       False  \n",
       "3  ../data/train_data_set/20170625-BBM-bm-n-mobo/...      0       False  \n",
       "4  ../data/train_data_set/20170625-BBM-bm-n-mobo/...      0       False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = load_img(all_pairs.loc[random.randint(0, len(all_pairs))]['fPath1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 1536)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_file.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img_file.resize([224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data_df, batch_size, is_test):\n",
    "    # initialize 2 empty arrays for the input batch\n",
    "    pairs=[np.zeros((batch_size, 224, 224, 3)).astype(\"int32\") for i in range(2)]\n",
    "    \n",
    "    # initialize vector for the targets - target is a 1 or 0 for match or not matched\n",
    "    targets=np.zeros((batch_size,))\n",
    "    \n",
    "    i=0\n",
    "    while i<batch_size:\n",
    "        data = data_df.loc[random.randint(0, len(data_df))]\n",
    "        if data['test_label']==is_test:\n",
    "            pairs[0][i,:,:,:] = load_img(data['fPath1']).resize([224, 224])\n",
    "            pairs[1][i,:,:,:] = load_img(data['fPath2']).resize([224, 224])\n",
    "            label = data['label']\n",
    "            i+=1\n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate batches:\n",
    "#select a random file\n",
    "#find the next file in the sqeuence (see if there is a common pattern to do this via the name))\n",
    "#if there is not a next file, start over\n",
    "#convert both files to keras images\n",
    "#apply the same random transformation to both images\n",
    "#apply a label\n",
    "#return pairs, labels\n",
    "\n",
    "#alternatively, draw random samples from a paired and labeled \n",
    "#pandas dataframe/numpy array. \n",
    "#Oceane's doesn't seem to be sequential, see what Will built, or build own\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(data_df, batch_size, is_test):\n",
    "    while True:\n",
    "        pairs, targets = get_batch(data_df, batch_size, is_test)\n",
    "        yield (pairs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batches(all_pairs, 32, False)\n",
    "\n",
    "val_gen = generate_batches(all_pairs, 32, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model architecture:\n",
    "\n",
    "def get_twin_model():\n",
    "    \n",
    "    image_width=224\n",
    "    image_height=224\n",
    "    input_shape = (image_width, image_height, 3)\n",
    "    \n",
    "    # Define the tensors for the two input documents\n",
    "    left_input = Input(IMAGE_SHAPE)\n",
    "    right_input = Input(IMAGE_SHAPE)\n",
    "    \n",
    "    # VGG Neural Network\n",
    "    model = VGG16(input_shape=IMAGE_SHAPE, include_top=False,weights='imagenet')\n",
    "    \n",
    "    model = Sequential([VGG16(input_shape=IMAGE_SHAPE, include_top=False,weights='imagenet'),\n",
    "                       GlobalAveragePooling2D()])\n",
    "###    model.add(VGGsomething...)\n",
    "###    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape))\n",
    "#     model.add(MaxPooling2D())\n",
    "#     model.add(Conv2D(128, (7,7), activation='relu'))\n",
    "#     model.add(MaxPooling2D())\n",
    "#     model.add(Conv2D(128, (4,4), activation='relu'))\n",
    "#     model.add(MaxPooling2D())\n",
    "#     model.add(Conv2D(256, (4,4), activation='relu'))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(4096, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two documents\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    twin_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return twin_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 512)          14714688    input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 512)          0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            513         lambda_3[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 14,715,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_twin_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"VGG16_batch32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "stopper = EarlyStopping(monitor='val_acc', patience=5)\n",
    "checkpointer = ModelCheckpoint(\"checkpoints/{}_continued.h5\".format(model_name), monitor='val_acc', save_best_only=True, period = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "#adjust training parameters\n",
    "history = model.fit_generator(train_gen, steps_per_epoch = 300, \\\n",
    "                              epochs = 50, verbose = 1, \\\n",
    "#                               callbacks=[tensorboard, stopper, checkpointer], \\\n",
    "                              callbacks=[stopper, checkpointer], \\\n",
    "                              validation_data = val_gen, validation_steps = 100, \\\n",
    "                              use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix filepath\n",
    "model.save(\"../../dbfs/mnt/databricks-cc/katelyn/ManuscriptMatcher/{}_final.h5\".format(model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
