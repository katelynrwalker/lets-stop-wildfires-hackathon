{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dropout, Dense, Input, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = pd.read_csv(\"oceane/combinations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1498413993_-02400.jpg</td>\n",
       "      <td>1498413993_-02400.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1498413993_-02400.jpg</td>\n",
       "      <td>1498414053_-02340.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1498413993_-02400.jpg</td>\n",
       "      <td>1498414113_-02280.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1498413993_-02400.jpg</td>\n",
       "      <td>1498414173_-02220.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1498413993_-02400.jpg</td>\n",
       "      <td>1498414233_-02160.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 image1                 image2  label\n",
       "0           0  1498413993_-02400.jpg  1498413993_-02400.jpg    0.0\n",
       "1           1  1498413993_-02400.jpg  1498414053_-02340.jpg    0.0\n",
       "2           2  1498413993_-02400.jpg  1498414113_-02280.jpg    0.0\n",
       "3           3  1498413993_-02400.jpg  1498414173_-02220.jpg    0.0\n",
       "4           4  1498413993_-02400.jpg  1498414233_-02160.jpg    0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231027"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110959</th>\n",
       "      <td>134002</td>\n",
       "      <td>1571849530.jpg</td>\n",
       "      <td>1571856730.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144648</th>\n",
       "      <td>167691</td>\n",
       "      <td>1572616812.jpg</td>\n",
       "      <td>1572614472.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208450</th>\n",
       "      <td>231493</td>\n",
       "      <td>1572713675.jpg</td>\n",
       "      <td>1572716615.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54715</th>\n",
       "      <td>72050</td>\n",
       "      <td>1563221843_-00960.jpg</td>\n",
       "      <td>1563222863_+00060.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172478</th>\n",
       "      <td>195521</td>\n",
       "      <td>1572636875.jpg</td>\n",
       "      <td>1572642695.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53014</th>\n",
       "      <td>70274</td>\n",
       "      <td>1563124927_+02340.jpg</td>\n",
       "      <td>1563123487_+00900.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12068</th>\n",
       "      <td>15835</td>\n",
       "      <td>1512675724_+01740.jpg</td>\n",
       "      <td>1512674824_+00840.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26268</th>\n",
       "      <td>34472</td>\n",
       "      <td>1530739045_+00000.jpg</td>\n",
       "      <td>1530739225_+00180.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69966</th>\n",
       "      <td>89809</td>\n",
       "      <td>1564868559_-00660.jpg</td>\n",
       "      <td>1564868919_-00300.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34642</th>\n",
       "      <td>45359</td>\n",
       "      <td>1532544985_+00060.jpg</td>\n",
       "      <td>1532545705_+00780.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                 image1                 image2  label\n",
       "110959      134002         1571849530.jpg         1571856730.jpg    0.0\n",
       "144648      167691         1572616812.jpg         1572614472.jpg    0.0\n",
       "208450      231493         1572713675.jpg         1572716615.jpg    0.0\n",
       "54715        72050  1563221843_-00960.jpg  1563222863_+00060.jpg    1.0\n",
       "172478      195521         1572636875.jpg         1572642695.jpg    0.0\n",
       "53014        70274  1563124927_+02340.jpg  1563123487_+00900.jpg    1.0\n",
       "12068        15835  1512675724_+01740.jpg  1512674824_+00840.jpg    1.0\n",
       "26268        34472  1530739045_+00000.jpg  1530739225_+00180.jpg    1.0\n",
       "69966        89809  1564868559_-00660.jpg  1564868919_-00300.jpg    0.0\n",
       "34642        45359  1532544985_+00060.jpg  1532545705_+00780.jpg    1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['149841',\n",
       " '149954',\n",
       " '151267',\n",
       " '152875',\n",
       " '152899',\n",
       " '152900',\n",
       " '152901',\n",
       " '152902',\n",
       " '153073',\n",
       " '153074',\n",
       " '153089',\n",
       " '153090',\n",
       " '153254',\n",
       " '155916',\n",
       " '156295',\n",
       " '156296',\n",
       " '156312',\n",
       " '156313',\n",
       " '156322',\n",
       " '156468',\n",
       " '156486',\n",
       " '156487',\n",
       " '156572',\n",
       " '156573',\n",
       " '157142',\n",
       " '157143',\n",
       " '157184',\n",
       " '157185',\n",
       " '157261',\n",
       " '157262',\n",
       " '157263',\n",
       " '157264',\n",
       " '157271',\n",
       " '157272']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(combos.image1.apply(lambda s: s[:6]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190529-94Fire-lp-s-mobo-c\n",
      "20191102-bm-e-mobo-c-2 \n",
      "20180614-Bridle-hp-n-mobo-c\n"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "random.seed(18)\n",
    "for folder in os.listdir(\"data/train_data_set/\"):\n",
    "    if random.random() < 0.8:\n",
    "        for f in os.listdir(\"data/train_data_set/\" + folder):\n",
    "            train_files.append(\"{}/{}\".format(folder, f))\n",
    "    else:\n",
    "        print(folder)\n",
    "        for f in os.listdir(\"data/train_data_set/\" + folder):\n",
    "            val_files.append(\"{}/{}\".format(folder, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1898"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_df = pd.DataFrame(train_files, columns=[\"file\"])\n",
    "train_files_df[\"smoke\"] = train_files_df.file.str[-10] == \"+\"\n",
    "\n",
    "val_files_df = pd.DataFrame(val_files, columns=[\"file\"])\n",
    "val_files_df[\"smoke\"] = val_files_df.file.str[-10] == \"+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageDataGenerator is useful for preprocessing the images into the right format, and also for applying random transformations to increase the variation in the training data.\n",
    "\n",
    "However - flow, flow_from_directory, and flow_from_dataframe all seem to be oriented at bringing in one image at a time, with it's label (flow MIGHT be more flexible on this, but needs to take in a numpy array that represents the image, not just an image file name).\n",
    "\n",
    "The one-shot network takes input from a generator that yields (pair, target) - so need to look into if that pair can be fed into the ImageDataGenerator.flow() method.\n",
    "\n",
    "Alternatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    rotation_range=40)\n",
    "\n",
    "validate_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.DataFrameIterator at 0xb312deda0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_generator.flow_from_dataframe(train_files_df, \"data/train_data_set/\", x_col=\"file\", y_col=\"smoke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2214 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.DirectoryIterator at 0xb336e2518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_generator.flow_from_directory(\"data/train_data_set_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#create a base model\n",
    "image_width=224\n",
    "image_height=224\n",
    "IMAGE_SHAPE = (image_width, image_height, 3)\n",
    "base_model = VGG16(input_shape=IMAGE_SHAPE, include_top=False,weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "JPEG\n",
      "RGB\n",
      "(3072, 2048)\n"
     ]
    }
   ],
   "source": [
    "# example of loading an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "# load the image\n",
    "img = load_img('data/train_data_set/'+train_files[0])\n",
    "# report details about the image\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "# show the image\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "float32\n",
      "(2048, 3072, 3)\n",
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "# example of converting an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "# load the image\n",
    "img = load_img('data/train_data_set/'+train_files[0])\n",
    "print(type(img))\n",
    "# convert to numpy array\n",
    "img_array = img_to_array(img)\n",
    "print(img_array.dtype)\n",
    "print(img_array.shape)\n",
    "# convert back to image\n",
    "img_pil = array_to_img(img_array)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img.rotate(90)\n",
    "img2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate batches:\n",
    "#select a random file\n",
    "#find the next file in the sqeuence (see if there is a common pattern to do this via the name))\n",
    "#if there is not a next file, start over\n",
    "#convert both files to keras images\n",
    "#apply the same random transformation to both images\n",
    "#apply a label\n",
    "#return pairs, labels\n",
    "\n",
    "#alternatively, draw random samples from a paired and labeled \n",
    "#pandas dataframe/numpy array. \n",
    "#Oceane's doesn't seem to be sequential, see what Will built, or build own\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust\n",
    "def generate_batches(batch_size, X, y, class_lookup_dict):\n",
    "  while True:\n",
    "      pairs, targets = get_batch(batch_size, X, y, class_lookup_dict)\n",
    "      yield (pairs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust parameters\n",
    "train_gen = generate_batches(train_batch_size, Xtrain_abs, ytrain, class_lookup_dict_train)\n",
    "\n",
    "val_gen = generate_batches(test_batch_size, Xval_abs, yval, class_lookup_dict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model architecture:\n",
    "\n",
    "def get_twin_model():\n",
    "    \n",
    "    image_width=224\n",
    "    image_height=224\n",
    "    IMAGE_SHAPE = (image_width, image_height, 3)\n",
    "    \n",
    "    # Define the tensors for the two input documents\n",
    "    left_input = Input(IMAGE_SHAPE)\n",
    "    right_input = Input(IMAGE_SHAPE)\n",
    "    \n",
    "    # VGG Neural Network\n",
    "    model = VGG16(input_shape=IMAGE_SHAPE, include_top=False,weights='imagenet')\n",
    "    \n",
    "###    model = Sequential()\n",
    "###    model.add(VGGsomething...)\n",
    "###    model.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two documents\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    twin_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return twin_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 7, 7, 512)    14714688    input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 7, 7, 512)    0           vgg16[1][0]                      \n",
      "                                                                 vgg16[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7, 7, 1)      513         lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 14,715,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_twin_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix filepaths\n",
    "optimizer = Adam()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "stopper = EarlyStopping(monitor='val_acc', patience=5)\n",
    "checkpointer = ModelCheckpoint(\"../../dbfs/mnt/databricks-cc/katelyn/ManuscriptMatcher/{}_continued.h5\".format(model_name), monitor='val_acc', save_best_only=True, period = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust training parameters\n",
    "history = model.fit_generator(train_gen, steps_per_epoch = 300, \\\n",
    "                              epochs = 50, verbose = 1, \\\n",
    "                              callbacks=[tensorboard, stopper, checkpointer], \\\n",
    "                              validation_data = val_gen, validation_steps = 100, \\\n",
    "                              use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix filepath\n",
    "model.save(\"../../dbfs/mnt/databricks-cc/katelyn/ManuscriptMatcher/{}_final.h5\".format(model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
